{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.0])\n",
    "y = x**2\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.0],requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors does not require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2.0\u001b[39m])\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m*\u001b[39mx\n\u001b[0;32m----> 4\u001b[0m dydx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    493\u001b[0m         grad_outputs_\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    509\u001b[0m     ):\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "x = torch.tensor([2.0])\n",
    "y = w*x\n",
    "dydx = torch.autograd.grad(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = w*x\n",
    "dydx = torch.autograd.grad(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m*\u001b[39mx\n\u001b[0;32m----> 4\u001b[0m dydx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:469\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    460\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    468\u001b[0m grad_outputs_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_outputs, \u001b[38;5;28mlen\u001b[39m(outputs))\n\u001b[0;32m--> 469\u001b[0m grad_outputs_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:198\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    196\u001b[0m     out_numel_is_1 \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_numel_is_1:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_dtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    202\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.5], requires_grad=True)\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = w*x\n",
    "dydx = torch.autograd.grad(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([1.5], requires_grad=True)\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = w*x\n",
    "dydx = torch.autograd.grad(y, x, grad_outputs=torch.ones_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(2, 3)\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35231/190733485.py:3: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  x = np.array(x)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/comphy/Comphy/myenv/lib/python3.12/site-packages/torch/_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "x = x.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1.0000, 1.5000, 2.0000])\n",
      "tensor([1.0000, 1.5000])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2)\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(3)\n",
    "print(ones)\n",
    "\n",
    "asdf = torch.linspace(1,2,3) # 3 values evenly spaced from 1.0 to 2.0\n",
    "print(asdf)\n",
    "\n",
    "qwer = torch.arange(1,2,0.5) # generates a 1D tensor with values starting at 1.0, incrementing by 0.5, and stopping before 2.0\n",
    "print(qwer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weight (w): 1.985772967338562\n",
      "Optimized bias (b): 0.03234156221151352\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple linear model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.w = nn.Parameter(torch.tensor(1.0, requires_grad=True))  # weight\n",
    "        self.b = nn.Parameter(torch.tensor(0.0, requires_grad=True))  # bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "# Create model instance\n",
    "line = LinearModel()\n",
    "\n",
    "# Define data, loss, and optimizer\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([2.0, 4.0, 6.0])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(line.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = line(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Inspect the optimized parameters\n",
    "print(\"Optimized weight (w):\", line.w.item())\n",
    "print(\"Optimized bias (b):\", line.b.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch-Geometric installed successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "print(\"Torch-Geometric installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Neural Nets: Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn.aggr import SumAggregation"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 A graph in Torch Geometric\n",
    "\n",
    "This is an example of a graph:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "edge_index = np.array([[0, 1],\n",
    "                       [1, 0],\n",
    "                       [1, 2],\n",
    "                       [2, 1]])\n",
    "edge_index = torch.tensor(edge_index.T, dtype=torch.long)\n",
    "\n",
    "graph = Data(x=x, edge_index=edge_index)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where edge_index gives pairs of (from-node, to-node) indices, and where x contains the node-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the graph\n",
    "\n",
    "You can get to know about the content and topology of your graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "graph['x']= tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index\n",
      "graph['edge_index']= tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "y\n",
      "graph['y']= 42\n",
      "pos\n",
      "graph['pos']= [[0.  0. ]\n",
      " [1.  0.5]\n",
      " [2.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key, item in graph:\n",
    "    print(key)\n",
    "    print(f\"graph['{key}']=\",item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x\n",
    "graph['x']= torch.tensor([[-1.],\n",
    "                   [ 0.],\n",
    "                   [ 1.]])\n",
    "edge_index\n",
    "graph['edge_index']= torch.tensor([[0, 1, 1, 2],\n",
    "                             [1, 0, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Adjacency matrix\n",
    "\n",
    "Use the to_dense_adj function to get the entire adjacency matrix from the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix = to_dense_adj(graph.edge_index)\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to e.g. find the spectrum of the adjacency matrix, here if it is symmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4142135e+00, -8.0664642e-17,  1.4142135e+00]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig = np.linalg.eigvalsh(adj_matrix)\n",
    "eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 More info on a graph\n",
    "\n",
    "The Data class is prepared for storing more information, e.g. a property, y, and some meta-information about the positions, pos, of the nodes in some space. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4], y=42, pos=[3, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 42\n",
    "pos = np.array([[0,0], [1, 0.5], [2, 0]])\n",
    "graph = Data(x=x, edge_index=edge_index, y=y, pos=pos)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the positions can be used for plotting. You can write your own function for that, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(ax, graph):\n",
    "\n",
    "    # Plot the nodes:\n",
    "    for idx, pos in enumerate(graph.pos):\n",
    "        ax.scatter(pos[0], pos[1], c='C1', s=1000)\n",
    "        ax.text(pos[0], pos[1], f'{idx}', color='w', ha='center', va='center')    \n",
    "    \n",
    "    # Plot the edges:\n",
    "    for idx, (i1,i2) in enumerate(graph.edge_index.T):\n",
    "        ax.plot([graph.pos[i1,0], graph.pos[i2,0]], [graph.pos[i1,1], graph.pos[i2,1]], c='black', zorder=0)\n",
    "\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "plot_graph(ax, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Dataloader\n",
    "\n",
    "Torch Geometric has its own Dataloader. Assume that you set up a list of three graphs, list_of_graphs, then the Dataloader is used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[6, 1], edge_index=[2, 8], y=[2], pos=[2], batch=[6], ptr=[3])\n",
      "DataBatch(x=[3, 1], edge_index=[2, 4], y=[1], pos=[1], batch=[3], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "list_of_graphs = [graph, graph, graph]\n",
    "loader = DataLoader(list_of_graphs, batch_size=2, shuffle=True)\n",
    "\n",
    "# iterate over it\n",
    "for batch in loader:\n",
    "     print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the DataBatch presents itself almost as the class for the graphs, Data, did. In fact, DataBatch, is just larger, unconnected, graphs. In the example, we have 3 graphs and a batch size of 2, so the first batch is a graph with twice the size of the original graph, while the second batch is just the final graph in the dataset.\n",
    "\n",
    "You may inspect some attributes on the first DataBatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edges: tensor([[0, 1, 1, 2, 3, 4, 4, 5],\n",
      "        [1, 0, 2, 1, 4, 3, 5, 4]])\n",
      "batch: tensor([0, 0, 0, 1, 1, 1])\n",
      "ptr: tensor([0, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print('x:',batch.x)\n",
    "    print('edges:',batch.edge_index)\n",
    "    print('batch:',batch.batch)\n",
    "    print('ptr:',batch.ptr)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the batch attribute annotate each node with an index of the graph it belongs to, and the ptr gives the node-index to start from and end at if the nodes belonging to one specific graph are to be extracted. If you use standard Torch Geometric classes and functions, you will not have to manipulate the graphs at an individual level for a batch of graphs, but the knowledge of what is provided by DataBatch is important for understanding when you print out intermediate results while coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Why is DataBatch a larger graph?\n",
    "\n",
    "The trick in Torch Geometric's batching is to represent the adjacency matrix of each graph appearing as a block in a large sparse block diagonal adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 1.],\n",
      "         [0., 0., 0., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    adj_matrix = to_dense_adj(batch.edge_index)\n",
    "    print(adj_matrix)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Message passing\n",
    "\n",
    "To illustrate message passing, consider the 3-node graph from above, but now with new node values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[5], [20], [100]], dtype=torch.float)\n",
    "graph.x = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class for passing messages may be written like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMessagePassing(MessagePassing):\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when instantiated, the type of aggregation must be defined, e.g. that messages are added up for nodes with several incoming edges, which is done with aggr='add':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_message_passing = CustomMessagePassing(aggr='add')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the messages can be sent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.],\n",
       "        [105.],\n",
       "        [ 20.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_message_passing(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where all edges (as specified by the edge_index attribute) lead to a message being sent from the source node to target node. Thus, the end-nodes in the graph, each receive the x=20. from the middle-node, while the middle node receives messages from each of the two end-nodes, x=5. and x=100., respectively, which are added up (because the class was instantiated with aggr='add'.\n",
    "\n",
    "Note: By saying \"sent ... to the target node\" we are making an abstraction, because as you see, nothing is sent anywhere, only a torch tensor is constructed and written out in the cell. But each entry in the tensor represents a node in the graph, and the tensor could be used to update the node values as a layer in an nn.Module-based model.\n",
    "\n",
    "Changing the aggregation method to multiplication it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.],\n",
       "        [500.],\n",
       "        [ 20.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_message_passing = CustomMessagePassing(aggr='mul')\n",
    "custom_message_passing(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other aggregation options are: 'min', 'max', and 'mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.0000],\n",
       "        [52.5000],\n",
       "        [20.0000]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_message_passing = CustomMessagePassing(aggr='mean')\n",
    "custom_message_passing(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8 Aggregation\n",
    "\n",
    "As a final operation required, consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  5.],\n",
       "         [ 20.],\n",
       "         [100.]]),\n",
       " tensor([[125.]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr = SumAggregation()\n",
    "graph.x, aggr(graph.x, graph.batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which adds up the node values, x, on all nodes for each graph. The graph.batch-argument assures that it is done correctly for batches of graphs.\n",
    "\n",
    "In case you stumble across it: Torch Geometric has a function that does the exact same thing as a SumAggregation instance. The function is called global_add_pool and is imported and used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_add_pool\n",
    "graph_level_features = global_add_pool(graph.x, graph.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, performing aggregation as a mean rather than as a sum, you might come across the MeanAggregation class and the global_mean_pool function that both do that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
